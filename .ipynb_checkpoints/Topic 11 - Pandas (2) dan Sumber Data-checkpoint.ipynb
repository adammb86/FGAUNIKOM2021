{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e293eda8",
   "metadata": {},
   "source": [
    "# Pembacaan Data dari File di Pandas\n",
    "\n",
    "Pandas memiliki kelebihan yaitu dapat menampung data hasil bacaan dari file yang kemudian nilainya akan diproses dalam struktur data series atau dataframe. Ada beberapa jenis file yang didukung oleh pandas dan dua di antaranya yang paling sering digunakan adalah file CSV dan Excel. Berikut adalah pembahasan tentang bagaimana suatu file dibaca oleh pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2038fa45",
   "metadata": {},
   "source": [
    "## File CSV\n",
    "\n",
    "Salah satu tipe file yang paling populer dalam data science adalah file csv. File csv berstruktur mirip seperti tabel (secara logika) dengan memanfaatkan karakter ``,`` (koma) atau ``;`` (titik koma) sebagai pemisah data antar kolom. Sebagai contoh, silakan perhatikan contoh file CSV berikut:\n",
    "\n",
    "<b>produk.csv</b>\n",
    "\n",
    "```csv\n",
    "kode_produk,nama_produk,jumlah\n",
    "A,AC,10\n",
    "B,Becak,3\n",
    "C,Charger,25\n",
    "D,Dadu,100\n",
    "E,Engsel Pintu,5\n",
    "\n",
    "```\n",
    "\n",
    "atau bisa juga seperti ini:\n",
    "\n",
    "<b>product2.csv</b>\n",
    "\n",
    "```csv\n",
    "kode_produk;nama_produk;jumlah\n",
    "A;AC;10\n",
    "B;Becak;3\n",
    "C;Charger;25\n",
    "D;Dadu;100\n",
    "E;Engsel Pintu;5\n",
    "\n",
    "```\n",
    "\n",
    "File csv biasanya diawali dengan baris header untuk menyatakan nama kolom dan diikuti dengan baris data setelahnya. Untuk memisahkan antar baris data, file csv menggunakan 1 karakter enter. Perhatikan juga bahwa pemberian karakter enter diberikan juga pada baris data terakhir. Penggunaan delimiter harus seragam dalam sebuah CSV. Pandas mempunyai fungsi ``read_csv()`` untuk melakukan pembacaan data dari file CSV. Berikut contoh penggunaannya:\n",
    "\n",
    "><b>Catatan:</b> Buat dahulu file product.csv dan product2.csv (copy-paste saja datanya termasuk enter) menggunakan data yang sudah disebutkan sebelumnya dan simpan di folder yang sama dengan file .ipynb atau .py anda untuk mempermudah pengaksesan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "861140a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kode_produk</th>\n",
       "      <th>nama_produk</th>\n",
       "      <th>jumlah</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>AC</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>Becak</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>Charger</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>Dadu</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>Engsel Pintu</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kode_produk   nama_produk  jumlah\n",
       "0           A            AC      10\n",
       "1           B         Becak       3\n",
       "2           C       Charger      25\n",
       "3           D          Dadu     100\n",
       "4           E  Engsel Pintu       5"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'product.csv'\n",
    "data_produk = pd.read_csv(file_path)\n",
    "\n",
    "data_produk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440a70f5",
   "metadata": {},
   "source": [
    "Untuk mengakses data pada file CSV yang memiliki delimiter berupa tanda ``;``, maka kita menambahkan parameter ``delimiter`` sebagai berikut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baedd269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kode_produk</th>\n",
       "      <th>nama_produk</th>\n",
       "      <th>jumlah</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>AC</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>Becak</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>Charger</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>Dadu</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>Engsel Pintu</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kode_produk   nama_produk  jumlah\n",
       "0           A            AC      10\n",
       "1           B         Becak       3\n",
       "2           C       Charger      25\n",
       "3           D          Dadu     100\n",
       "4           E  Engsel Pintu       5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'product2.csv'\n",
    "data_produk = pd.read_csv(file_path, delimiter = ';')\n",
    "\n",
    "data_produk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55035e6",
   "metadata": {},
   "source": [
    "Untuk mengetahui secara lengkap perihal parameter yang ada di read_csv, silakan kunjungi https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html. Selain melakukan pembacaan, pandas menyediakan cara untuk menuliskan dataframe ke dalam file CSV. fungsi yang digunakan adalah ``to_csv()``. Berikut contoh penggunaannya:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4e3159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'col1':[1,2,3,4,5,6],'col2':[444,555,666,444,333,555],'col3':['abc','def','ghi','xyz','mno','jkl']})\n",
    "df\n",
    "\n",
    "df.to_csv('coba.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f320d0",
   "metadata": {},
   "source": [
    "Penjelasan:\n",
    "\n",
    "1. Parameter pertama pada fungsi ``to_csv()`` adalah nama file yang mau diberikan untuk menyimpan dataframe.\n",
    "2. Parameter ``index = False`` digunakan untuk menandakan index pada dataframe tidak ikut disimpan ke dalam file CSV.\n",
    "3. Kode program tadi akan menghasilkan file ``coba.csv`` yang isinya dapat dilihat pada gambar berikut:\n",
    "\n",
    "![tampilan coba.csv](https://drive.google.com/uc?export=view&id=1AH_E73_pk-ERyMN6YkQe_AyBfv9Jon0b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cf3d7e",
   "metadata": {},
   "source": [
    "## File Excel\n",
    "\n",
    "Selain file CSV, pandas juga bisa melakukan pengolah data dari dan ke file Excel. Fungsi yang digunakan untuk membaca data dari file excel adalah ``read_excel()``. Yang perlu diingat, fungsi ini hanya membaca data saja dan tidak membaca formula. Berikut contoh penggunaannya:\n",
    "\n",
    "Unduh file product.xlsx dari https://github.com/adammb86/FGAUNIKOM2021/blob/master/product.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89249408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kode_produk</th>\n",
       "      <th>nama_produk</th>\n",
       "      <th>jumlah</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>AC</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>Becak</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>Charger</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>Dadu</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>Engsel Pintu</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kode_produk   nama_produk  jumlah\n",
       "0           A            AC      10\n",
       "1           B         Becak       3\n",
       "2           C       Charger      25\n",
       "3           D          Dadu     100\n",
       "4           E  Engsel Pintu       5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_produk = pd.read_excel('product.xlsx', sheet_name = 'product')\n",
    "data_produk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e736201a",
   "metadata": {},
   "source": [
    "><b>Catatan:</b> Parameter ``sheet_name`` diisi dengan nama sheet yang mau dibaca (dalam 1 file excel bisa terdapat banyak sheet)\n",
    "\n",
    "Untuk melakukan penulisan dataframe ke dalam file excel, pandas menyediakan fungsi ``to_excel()`` yang penggunaanya sebagai berikut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5080ecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'col1':[1,2,3,4,5,6],'col2':[444,555,666,444,333,555],'col3':['abc','def','ghi','xyz','mno','jkl']})\n",
    "df\n",
    "\n",
    "df.to_excel('coba.xlsx', sheet_name = 'coba', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fe3482",
   "metadata": {},
   "source": [
    "Kode program tersebut akan menghasilkan sebuah file bernama ``coba.xlsx`` yang berisi seperti gambar berikut:\n",
    "\n",
    "![tampilan coba.xlsx](https://drive.google.com/uc?export=view&id=17x3T9OsIGBl1iKLQyfweR3ab_eARZgsy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f819976",
   "metadata": {},
   "source": [
    "# Sumber Data\n",
    "\n",
    "Kita sudah mempelajari bagaimana cara membaca data dari file CSV dan Excel ke dalam dataframe begitu pun menulis dataframe ke kedua format file tersebut. Pertanyaan berikutnya yang muncul adalah bagaimana cara mendapatkan data untuk kita olah. Tentunya kita bisa membuat file secara manual ataupun dengan cara melakukan export data dari DBMS. Akan tetapi ada suatu kemungkinan yaitu kita tidak mempunyai sumber data untuk diolah. \n",
    "\n",
    "Di internet tersedia banyak sumber data yang bersifat open dan legal untuk digunakan dalam berlatih pengolahan data di pandas. Berikut adalah beberapa sumber data yang bisa digunakan secara public dan legal:\n",
    "\n",
    "1. Portal Satu Data Indonesia (https://data.go.id) \n",
    "2. Portal Data Jakarta (https://data.jakarta.go.id) \n",
    "3. Portal Data Bandung (http://data.bandung.go.id)  \n",
    "4. Badan Pusat Statistik (https://www.bps.go.id)  \n",
    "5. Badan Informasi Geospasial (https://tanahair.indonesia.go.id/)  \n",
    "6. UCI Machine Learning repository (https://archive.ics.uci.edu/ml/index.php) \n",
    "7. Kaggle (https://www.kaggle.com/datasets)  \n",
    "8. World Bank Open Data (https://data.worldbank.org)  \n",
    "9. UNICEF Data (https://data.unicef.org) \n",
    "10. WHO Open Data (https://www.who.int/data)  \n",
    "11. IBM Data Asset eXchange (https://developer.ibm.com/exchanges/data/) \n",
    "12. DBPedia (https://www.dbpedia.org/resources/)  \n",
    "13. Wikidata (https://www.wikidata.org/)\n",
    "14. Google Dataset (https://datasetsearch.research.google.com/)\n",
    "\n",
    "Bentuk datanya bermacam-macam, akan tetapi sangat disarankan untuk menggunakan format data CSV atau excel untuk mempermudah proses pengolahan data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72a553b",
   "metadata": {},
   "source": [
    "## Mengambil Data dari Kaggle\n",
    "\n",
    "Salah satu sumber data yang paling populer adalah Kaggle. Kaggle menyediakan berbagai jenis dataset yang bisa kita olah menggunakan Python. Platform Kaggle biasanya digunakan untuk platform kompetisi data science. Untuk bisa mengakses data dari Kaggle, Python memiliki library dengan nama yang sama yaitu  ``kaggle``. Berikut adalah cara pengambilan data dari Kaggle.\n",
    "\n",
    "1. Buka https://kaggle.com dan buat akun di website tersebut.\n",
    "2. Setelah membuat akun, maka kita bisa melihat tampilan sebagai berikut (tampilan bisa berubah):\n",
    "\n",
    "![tampilan dashboard kaggle](https://drive.google.com/uc?export=view&id=1mUmezwsudmh4plafUt6mhpr5AP6vBg5d)\n",
    "\n",
    "3. Kita bisa melakukan pencarian langsung melalui halaman tersebut. Berikut contoh pencariannya:\n",
    "\n",
    "![contoh search kaggle](https://drive.google.com/uc?export=view&id=1ZaJWYtH0s05HQ4PGR6wpqBcDZwr2fxZh)\n",
    "\n",
    "![unduh data kaggle](https://drive.google.com/uc?export=view&id=1b_TPjG_zRGjdyjqzAGyKGtdhdpTvbZtQ)\n",
    "\n",
    "\n",
    "Selain dengan menggunakan cara manual, kita bisa memanfaatkan API untuk mengunduh data dari Kaggle. Berikut langkah-langkahnya:\n",
    "\n",
    "1. Instalasi library kaggle menggunakan pip3 dengan perintah sebagai berikut:<br> ``pip3 install kaggle``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68b95166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: kaggle\r\n",
      "Version: 1.5.12\r\n",
      "Summary: Kaggle API\r\n",
      "Home-page: https://github.com/Kaggle/kaggle-api\r\n",
      "Author: Kaggle\r\n",
      "Author-email: support@kaggle.com\r\n",
      "License: Apache 2.0\r\n",
      "Location: /usr/local/anaconda3/lib/python3.8/site-packages\r\n",
      "Requires: tqdm, python-slugify, python-dateutil, urllib3, requests, six, certifi\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "!pip3 show kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea66f6be",
   "metadata": {},
   "source": [
    "2. Lakukan log in di Kaggle menggunakan akun yang sudah dibuat sebelumnya lalu klik foto profil (sebelah kanan atas), kemudian pilih Account lalu pada section API, pilih ``Create New API Token``. Langkah ini tidak perlu dilakukan apabila sudah pernah dilakukan sebelumnya.\n",
    "\n",
    "![contoh search kaggle](https://drive.google.com/uc?export=view&id=1j0kzZEeo5XnZId1Owph501zGwcrn6Iro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095d6a5b",
   "metadata": {},
   "source": [
    "3. File kaggle.json akan ada di folder Downloads masing-masing. Setelah itu copy file tersebut ke dalam: ``~/.kaggle/`` (Linux/Mac) atau ``C:\\Users\\<Windows-username>\\.kaggle\\`` (Windows). Jika folder tersebut belum ada, buat dulu dengan perintah mkdir di shell/command line. Pindahkan file kaggle.json ke folder tersebut (menggunakan File/Windows Explorer atau melalui perintah mv atau move di shell).\n",
    "\n",
    "![copy kaggle.json](https://drive.google.com/uc?export=view&id=1-AAlSy0gtfNalk1IN8vNhf6hyiXbRcR3)\n",
    "\n",
    "4. Sebelum mengunduh, mari kita cari dahulu dataset yang mau kita gunakan dengan menjalankan perintah sebagai berikut (Hilangkan tanda seru kalau mau menjalankan perintah berikut langsung di environment Python. Tanda seru hanya fitur di Jupyter Notebook untuk mengernali perintah CMD atau terminal di Jupyter Notebook):\n",
    "\n",
    "```python\n",
    "kaggle datasets list -s <keyword>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1229ec9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /Users/adambachtiar/.kaggle/kaggle.json'\n",
      "ref                                                           title                                                size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
      "------------------------------------------------------------  --------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
      "heesoo37/120-years-of-olympic-history-athletes-and-results    120 years of Olympic history: athletes and results    5MB  2018-06-15 06:10:41          74244       1489  0.8235294        \n",
      "jayrav13/olympic-track-field-results                          Olympic Track & Field Results                        80KB  2017-05-26 02:42:35           2794         48  0.7647059        \n",
      "divyansh22/summer-olympics-medals                             Summer Olympics Medals (1976-2008)                  219KB  2020-02-03 08:42:41           4510         94  0.9411765        \n",
      "the-guardian/olympic-games                                    Olympic Sports and Medals, 1896-2014                483KB  2017-01-24 15:05:37          19460        172  0.7058824        \n",
      "stefanzivanov/olympic-games-2021-medals                       Olympic Games 2021 Medals                             2KB  2021-08-08 18:36:05            625         28  1.0              \n",
      "berkayalan/2021-olympics-medals-in-tokyo                      Tokyo 2020 Olympics Medals                            1KB  2021-08-09 19:36:13            952         36  1.0              \n",
      "arjunprasadsarkhel/2021-olympics-in-tokyo                     2021 Olympics in Tokyo                              348KB  2021-08-17 19:25:37           2549         69  0.8235294        \n",
      "rio2016/olympic-games                                         2016 Olympics in Rio de Janeiro                     286KB  2017-01-09 19:35:12           8236         93  0.7058824        \n",
      "mysarahmadbhat/120-years-of-olympic-history                   120 Years of Olympic History                          5MB  2021-08-09 02:26:36            561         33  1.0              \n",
      "samruddhim/olympics-althlete-events-analysis                  Olympics Althlete Events Analysis                     5MB  2020-09-12 07:14:20            477         25  1.0              \n",
      "piterfm/olympic-results-biathlon                              Olympic Results Biathlon                              5KB  2018-09-17 10:39:56            271          5  1.0              \n",
      "gpreda/tokyo-olympics-2020-tweets                             Tokyo Olympics 2020 Tweets                           25MB  2021-07-28 18:22:30            266         15  1.0              \n",
      "rushikeshlavate/olympic-games-medal-datasetfrom-1896-to-2018  Olympic Games medal Dataset(from 1896 to 2018)        4KB  2021-01-03 05:56:23            667         22  0.7647059        \n",
      "brendan45774/summer-olympics-medalist-dataset                 Summer Olympics Medalist                              1MB  2021-05-29 19:59:38            152         19  0.8235294        \n",
      "mathurinache/women-in-the-olympic-games                       Women in the Olympic Games                          113KB  2021-03-14 21:02:10            104          9  1.0              \n",
      "martj42/international-football-results-from-1872-to-2017      International football results from 1872 to 2021    550KB  2021-08-07 14:41:33          43498       1297  1.0              \n",
      "mpwolke/cusersmarilonedriverea-de-trabalhomedalcsv            Olympic Medal Rewards                                513B  2021-07-28 13:33:43             13          2  1.0              \n",
      "piterfm/olympic-games-medals-19862018                         Olympic Games, 1986-2018                             10MB  2021-08-04 21:02:38             95          2  1.0              \n",
      "mathurinache/cross-country-skiing-at-the-winter-olympics      Cross-country_skiing_at_the_Winter_Olympics           2KB  2020-09-06 15:07:08             38         10  0.9411765        \n",
      "piterfm/olympic-games-hosts                                   Olympic Games Hosts                                   3KB  2020-04-24 20:46:29             89          1  1.0              \n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets list -s 'Olympic'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5568c4e",
   "metadata": {},
   "source": [
    "5. Setelah itu jalankan perintah untuk mengunduh dataset yang dimaksud. Sebagai contoh kita mau mengunduh dataset ``120 years of Olympic history: athletes and results`` maka jalankan perintah berikut:\n",
    "\n",
    "><b>Catatan:</b> alamat unduh bisa didapatkan dari operasi sebelumnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef55d60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /Users/adambachtiar/.kaggle/kaggle.json'\n",
      "Downloading 120-years-of-olympic-history-athletes-and-results.zip to /Users/adambachtiar/Documents/FGAUNIKOM2021\n",
      "100%|██████████████████████████████████████| 5.43M/5.43M [00:01<00:00, 3.45MB/s]\n",
      "100%|██████████████████████████████████████| 5.43M/5.43M [00:01<00:00, 4.18MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download heesoo37/120-years-of-olympic-history-athletes-and-results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c29ba09",
   "metadata": {},
   "source": [
    "6. Data yang diinginkan akan diunduh ke dalam folder yang sama dengan file .ipynb atau di Direktori aktif apabila perintah untuk mengunduh dijalankan di CMD atau Terminal. Pastikan file yang diunduh berada di folder yang sama dengan file project kita. File yang diunduh akan didapatkan dalam bentuk zip. Silakan unzip terlebih dahulu secara manual menggunakan winzip atau 7zip. Untuk pengguna Linux atau Mac OS bisa menggunakan perintah sebagai berikut:\n",
    "\n",
    "```python\n",
    "unzip nama_file.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1cb7466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  120-years-of-olympic-history-athletes-and-results.zip\n",
      "  inflating: athlete_events.csv      \n",
      "  inflating: noc_regions.csv         \n"
     ]
    }
   ],
   "source": [
    "!unzip 120-years-of-olympic-history-athletes-and-results.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87228c52",
   "metadata": {},
   "source": [
    "7. Langkah terakhir, silakan muat data ke dalam dataframe menggunakan perintah ``read_csv()`` seperti yang sudah dibahas sebelumnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94202d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Topic 2 - Data Types, Variables, Basic Input-Output Operations, Basic Operators.ipynb', 'Topic 9 - Numpy dan Scipy.ipynb', 'product2.csv', 'noc_regions.csv', 'halo.txt', 'product.xlsx', '.DS_Store', 'filebaru.txt', 'Topic 4 - Functions, Tuples, Dictionaries, Set and Data processing.ipynb', 'Topic 7 - Object Oriented Programming.ipynb', 'puisi.txt', 'Topic 8 - Miscellaneous.ipynb', 'Topic 3 - Boolean Values, Conditional Execution, Loops, Lists and List Processing, Logical and Bitwise Operations.ipynb', 'coba.xlsx', 'athlete_events.csv', 'Topic 10 - Pandas.ipynb', 'coba.csv', 'Topic 5 - Modules, Packages, and PIP.ipynb', '.ipynb_checkpoints', 'Topic 11 - Pandas (2) dan Sumber Data.ipynb', '120-years-of-olympic-history-athletes-and-results.zip', '.git', 'Topic 1 - Introdution to Python.ipynb', '.vscode', 'Topic 6 - String, String and List Method, Exceptions.ipynb', 'product.csv', 'binary.bin']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.listdir(os.getcwd())) # Pastikan anda sedang berada di direktori project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edd2d639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID                      Name Sex   Age  Height  Weight  \\\n",
      "0            1                 A Dijiang   M  24.0   180.0    80.0   \n",
      "1            2                  A Lamusi   M  23.0   170.0    60.0   \n",
      "2            3       Gunnar Nielsen Aaby   M  24.0     NaN     NaN   \n",
      "3            4      Edgar Lindenau Aabye   M  34.0     NaN     NaN   \n",
      "4            5  Christine Jacoba Aaftink   F  21.0   185.0    82.0   \n",
      "...        ...                       ...  ..   ...     ...     ...   \n",
      "271111  135569                Andrzej ya   M  29.0   179.0    89.0   \n",
      "271112  135570                  Piotr ya   M  27.0   176.0    59.0   \n",
      "271113  135570                  Piotr ya   M  27.0   176.0    59.0   \n",
      "271114  135571        Tomasz Ireneusz ya   M  30.0   185.0    96.0   \n",
      "271115  135571        Tomasz Ireneusz ya   M  34.0   185.0    96.0   \n",
      "\n",
      "                  Team  NOC        Games  Year  Season            City  \\\n",
      "0                China  CHN  1992 Summer  1992  Summer       Barcelona   \n",
      "1                China  CHN  2012 Summer  2012  Summer          London   \n",
      "2              Denmark  DEN  1920 Summer  1920  Summer       Antwerpen   \n",
      "3       Denmark/Sweden  DEN  1900 Summer  1900  Summer           Paris   \n",
      "4          Netherlands  NED  1988 Winter  1988  Winter         Calgary   \n",
      "...                ...  ...          ...   ...     ...             ...   \n",
      "271111        Poland-1  POL  1976 Winter  1976  Winter       Innsbruck   \n",
      "271112          Poland  POL  2014 Winter  2014  Winter           Sochi   \n",
      "271113          Poland  POL  2014 Winter  2014  Winter           Sochi   \n",
      "271114          Poland  POL  1998 Winter  1998  Winter          Nagano   \n",
      "271115          Poland  POL  2002 Winter  2002  Winter  Salt Lake City   \n",
      "\n",
      "                Sport                                     Event Medal  \n",
      "0          Basketball               Basketball Men's Basketball   NaN  \n",
      "1                Judo              Judo Men's Extra-Lightweight   NaN  \n",
      "2            Football                   Football Men's Football   NaN  \n",
      "3          Tug-Of-War               Tug-Of-War Men's Tug-Of-War  Gold  \n",
      "4       Speed Skating          Speed Skating Women's 500 metres   NaN  \n",
      "...               ...                                       ...   ...  \n",
      "271111           Luge                Luge Mixed (Men)'s Doubles   NaN  \n",
      "271112    Ski Jumping  Ski Jumping Men's Large Hill, Individual   NaN  \n",
      "271113    Ski Jumping        Ski Jumping Men's Large Hill, Team   NaN  \n",
      "271114      Bobsleigh                      Bobsleigh Men's Four   NaN  \n",
      "271115      Bobsleigh                      Bobsleigh Men's Four   NaN  \n",
      "\n",
      "[271116 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = 'athlete_events.csv'\n",
    "athlete_events = pd.read_csv(path)\n",
    "\n",
    "print(athlete_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa67f4e",
   "metadata": {},
   "source": [
    "Dokumentasi lebih lanjut tentang library ``kaggle`` di Python, dapat dilihat di https://github.com/Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577f2564",
   "metadata": {},
   "source": [
    "## Hands on Lab 1: Mari mengunduh data dari kaggle\n",
    "\n",
    "Silakan bereksperimen untuk mengunduh data yang Anda inginkan dari kaggle menggunakan API.\n",
    "\n",
    "1. Cari dataset yang diinginkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbebf7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e14d2255",
   "metadata": {},
   "source": [
    "2. Unduh salah satu data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffb2a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b67b3da5",
   "metadata": {},
   "source": [
    "3. Tampilkan dalam bentuk dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9761efc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36f08650",
   "metadata": {},
   "source": [
    "# Scrapping Data dari HTML\n",
    "\n",
    "Terkadang data yang diinginkan tidak tersedia dalam bentuk file, akan tetapi dalam bentuk sebuah halaman website. Kita bisa mengambil data dari halaman HTML menggunakan teknik scrapping. Untuk bisa menjalankan teknik scrapping di Python, kita membutuhkan beberapa library tambahan. Silakan lakukan instalasi library-library tersebut.\n",
    "\n",
    "```python\n",
    "conda install lxml\n",
    "conda install html5lib\n",
    "conda install BeautifulSoup4\n",
    "```\n",
    "\n",
    "Peritnah conda bisa diganti dengan ``pip3``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbd0e97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install lxml\n",
    "!conda install html5lib\n",
    "!conda install BeautifulSoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523b6f6d",
   "metadata": {},
   "source": [
    "Setelah melakukan instalasi, kita sudah bisa melakukan teknik scrapping. Sebagai contoh, kita mau mengunduh data dari https://www.fdic.gov/resources/resolutions/bank-failures/failed-bank-list/ (Silakan lihat daulu websitenya sebalum menjalankan kode program berikut):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f28ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_html('https://www.fdic.gov/resources/resolutions/bank-failures/failed-bank-list/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d36b1df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                         Bank NameBank           CityCity StateSt  CertCert  \\\n",
       " 0                    Almena State Bank             Almena      KS     15426   \n",
       " 1           First City Bank of Florida  Fort Walton Beach      FL     16748   \n",
       " 2                 The First State Bank      Barboursville      WV     14361   \n",
       " 3                   Ericson State Bank            Ericson      NE     18265   \n",
       " 4     City National Bank of New Jersey             Newark      NJ     21111   \n",
       " ..                                 ...                ...     ...       ...   \n",
       " 558                 Superior Bank, FSB           Hinsdale      IL     32646   \n",
       " 559                Malta National Bank              Malta      OH      6629   \n",
       " 560    First Alliance Bank & Trust Co.         Manchester      NH     34264   \n",
       " 561  National State Bank of Metropolis         Metropolis      IL      3815   \n",
       " 562                   Bank of Honolulu           Honolulu      HI     21029   \n",
       " \n",
       "                  Acquiring InstitutionAI Closing DateClosing  FundFund  \n",
       " 0                            Equity Bank    October 23, 2020     10538  \n",
       " 1              United Fidelity Bank, fsb    October 16, 2020     10537  \n",
       " 2                         MVB Bank, Inc.       April 3, 2020     10536  \n",
       " 3             Farmers and Merchants Bank   February 14, 2020     10535  \n",
       " 4                        Industrial Bank    November 1, 2019     10534  \n",
       " ..                                   ...                 ...       ...  \n",
       " 558                Superior Federal, FSB       July 27, 2001      6004  \n",
       " 559                    North Valley Bank         May 3, 2001      4648  \n",
       " 560  Southern New Hampshire Bank & Trust    February 2, 2001      4647  \n",
       " 561              Banterra Bank of Marion   December 14, 2000      4646  \n",
       " 562                   Bank of the Orient    October 13, 2000      4645  \n",
       " \n",
       " [563 rows x 7 columns]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d199c1e",
   "metadata": {},
   "source": [
    "# Koneksi Data ke MySQL/MariaDB\n",
    "\n",
    "Sebagai tambahan materi, mari kita mengambil data yang ada dalam DBMS. Pada contoh kali ini, kita akan berfokus kepada DBMS MySQL/MariaDB. Library yang mendukung hal ini adalah ``SQLAlchemy`` (di modul ini kita hanya berfokus ke pembacaan data saja, jadi modul ini bersifat opsional). Untuk bisa bekerja dengan baik, library ini membutuhkan driver yang sesuai dengan DBMS sumber data. Sebagai contoh, apabila kita menggunakan MySQL maka kita harus menambahkan driver pymysql. Dokumentasi SQLAlchemy dapat dilihat di https://docs.sqlalchemy.org/.\n",
    "\n",
    "Seperti biasa, lakukan instalasi library bersangkutan dengan conda ataupun pip3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f306b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in /usr/local/anaconda3/lib/python3.8/site-packages (1.4.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/anaconda3/lib/python3.8/site-packages (from sqlalchemy) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980d8363",
   "metadata": {},
   "source": [
    "Setelah itu lakukan intalasi Driver pymysql:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "128c32a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pymysql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb78a751",
   "metadata": {},
   "source": [
    "Silakan buat dahulu tabel di MySQL/MariaDB dengan cara meng-import file.sql yang ada di https://github.com/adammb86/webservicebpom/blob/main/webservices.sql. Setelah itu lakukan import library pymysql dan pandas (SQLAlchemy opsional karena hanya pembacaan data ke dataframe):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4e52597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "\n",
    "pymysql.install_as_MySQLdb()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc3a443",
   "metadata": {},
   "source": [
    "Buatlah koneksi ke MySQL sebagai berikut (Pastikan MySQL server sudah aktif apabila koneksi diarahkan ke localhost):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "558e5918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pymysql.connections.Connection object at 0x7fe0c02e13d0>\n"
     ]
    }
   ],
   "source": [
    "Host = \"localhost\"  \n",
    "User = \"root\"      \n",
    "Password = \"\"           \n",
    "database = \"webservices\"\n",
    "\n",
    "conn  = pymysql.connect(host=Host, user=User, password=Password, database= database)\n",
    "\n",
    "print(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdac284",
   "metadata": {},
   "source": [
    "Setelah membuat koneksi, maka kita bisa melakukan pengambilan data ke dalam dataframe dengan perintah berikut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "050aace5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jenis_produk</th>\n",
       "      <th>nama_produk</th>\n",
       "      <th>jumlah_stok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Minuman</td>\n",
       "      <td>Air Mineral</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Makanan</td>\n",
       "      <td>Snack Ringan</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  jenis_produk   nama_produk  jumlah_stok\n",
       "0      Minuman   Air Mineral          100\n",
       "1      Makanan  Snack Ringan           50"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_sql(\"SELECT jenis_produk, nama_produk, jumlah_stok FROM produk\", conn)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba99f4a",
   "metadata": {},
   "source": [
    "Selain bisa melakukan pembacaan dari MySQL, kita juga bisa melakukan penulisan dataframe ke table di MySQL. Berikut contoh penggunaannya:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bebee287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>444</td>\n",
       "      <td>abc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>555</td>\n",
       "      <td>def</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>666</td>\n",
       "      <td>ghi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>444</td>\n",
       "      <td>xyz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>333</td>\n",
       "      <td>mno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>555</td>\n",
       "      <td>jkl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2 col3\n",
       "0     1   444  abc\n",
       "1     2   555  def\n",
       "2     3   666  ghi\n",
       "3     4   444  xyz\n",
       "4     5   333  mno\n",
       "5     6   555  jkl"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'col1':[1,2,3,4,5,6],'col2':[444,555,666,444,333,555],'col3':['abc','def','ghi','xyz','mno','jkl']})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd160fb",
   "metadata": {},
   "source": [
    "# Pandas Cheat Sheet\n",
    "\n",
    "Untuk melengkapi pengetahuan sebelum masuk ke latihan pengolahan data menggunakan Pandas, silakan pelajari dahulu pandas cheat sheet berikut:\n",
    "\n",
    "![Pandas cheat sheet 1](https://drive.google.com/uc?export=view&id=1QoqqQIcuzT3xPtn6b2jUfSIlTYSyPN7b)\n",
    "\n",
    "![Pandas cheat sheet 2](https://drive.google.com/uc?export=view&id=1PgGQIXW9RC7cIwpWLdiu-6xl9q6-qdLA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
